{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë‹¤ì–‘í•œ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê°„ë‹¨í•œ ê·¸ë˜í”„ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from urllib.parse import quote\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "class GoogleNews:\n",
    "    \"\"\"\n",
    "    êµ¬ê¸€ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://news.google.com/rss\"\n",
    "\n",
    "    def _fetch_news(self, url: str, k: int = 3) -> List[Dict[str, str]]:\n",
    "        news_data = feedparser.parse(url)\n",
    "        return [\n",
    "            {\"title\": entry.title, \"link\": entry.link}\n",
    "            for entry in news_data.entries[:k]\n",
    "        ]\n",
    "\n",
    "    def _collect_news(self, news_list: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "\n",
    "        if not news_list:\n",
    "            print(\"í•´ë‹¹ í‚¤ì›Œë“œì˜ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return []\n",
    "\n",
    "        result = []\n",
    "        for news in news_list:\n",
    "            result.append({\"url\": news[\"link\"], \"content\": news[\"title\"]})\n",
    "\n",
    "        return result\n",
    "\n",
    "    def search_latest(self, k: int = 3) -> List[Dict[str, str]]:\n",
    "        url = f\"{self.base_url}?hl=ko&gl=KR&ceid=KR:ko\"\n",
    "        news_list = self._fetch_news(url, k)\n",
    "        return self._collect_news(news_list)\n",
    "\n",
    "    def search_by_keyword(\n",
    "        self, keyword: Optional[str] = None, k: int = 3\n",
    "    ) -> List[Dict[str, str]]:\n",
    "        if keyword:\n",
    "            encoded_keyword = quote(keyword)\n",
    "            url = f\"{self.base_url}/search?q={encoded_keyword}&hl=ko&gl=KR&ceid=KR:ko\"\n",
    "        else:\n",
    "            url = f\"{self.base_url}?hl=ko&gl=KR&ceid=KR:ko\"\n",
    "        news_list = self._fetch_news(url, k)\n",
    "        return self._collect_news(news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "########## 1. ìƒíƒœ ì •ì˜ ##########\n",
    "# ìƒíƒœ ì •ì˜\n",
    "class State(TypedDict):\n",
    "    # ë©”ì‹œì§€ ëª©ë¡ ì£¼ì„ ì¶”ê°€\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "########## 2. ë„êµ¬ ì •ì˜ ë° ë°”ì¸ë”© ##########\n",
    "# ë„êµ¬ ì´ˆê¸°í™”\n",
    "# í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ ìƒì„±\n",
    "@tool\n",
    "def search_keyword(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Look up news by keyword\"\"\"\n",
    "    news_tool = GoogleNews()\n",
    "    return \"\\n\".join([f'- {news[\"content\"]}' for news in news_tool.search_by_keyword(query, k=5)])\n",
    "\n",
    "\n",
    "# ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "tools = [search_keyword]\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# ë„êµ¬ì™€ LLM ê²°í•©\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "########## 3. ë…¸ë“œ ì¶”ê°€ ##########\n",
    "# ì±—ë´‡ í•¨ìˆ˜ ì •ì˜\n",
    "def chatbot(state: State):\n",
    "    # ë©”ì‹œì§€ í˜¸ì¶œ ë° ë°˜í™˜\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# ìƒíƒœ ê·¸ë˜í”„ ìƒì„±\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# ì±—ë´‡ ë…¸ë“œ ì¶”ê°€\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# ë„êµ¬ ë…¸ë“œ ìƒì„± ë° ì¶”ê°€\n",
    "tool_node = ToolNode(tools=[search_keyword])\n",
    "\n",
    "# ë„êµ¬ ë…¸ë“œ ì¶”ê°€\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "########## 4. ì—£ì§€ ì¶”ê°€ ##########\n",
    "\n",
    "# tools > chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# START > chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# chatbot > END\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ë‹¨ìˆœ ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_keyword (call_rmMkbD8nOZZfpjUzRm4MnU0i)\n",
      " Call ID: call_rmMkbD8nOZZfpjUzRm4MnU0i\n",
      "  Args:\n",
      "    query: AI\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_keyword\n",
      "\n",
      "- \"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì • - AIíƒ€ì„ìŠ¤\n",
      "- AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™ - í•œê²¨ë ˆ\n",
      "- [ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\" - ì¡°ì„ ì¼ë³´\n",
      "- ë„¤ì´ë²„, AI ìƒìš©í™” ë°©ì•ˆ ê³µê°œâ€¦\"ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤\" - SBS ë‰´ìŠ¤\n",
      "- íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì› - ë””ì§€í„¸íˆ¬ë°ì´\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ìµœì‹  AI ê´€ë ¨ ë‰´ìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **\"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì •** - AIíƒ€ì„ìŠ¤\n",
      "2. **AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™** - í•œê²¨ë ˆ\n",
      "3. **[ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\"** - ì¡°ì„ ì¼ë³´\n",
      "4. **ë„¤ì´ë²„, AI ìƒìš©í™” ë°©ì•ˆ ê³µê°œâ€¦\"ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤\"** - SBS ë‰´ìŠ¤\n",
      "5. **íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì›** - ë””ì§€í„¸íˆ¬ë°ì´\n",
      "\n",
      "ë” ë§ì€ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\"messages\": [(\"human\", \"AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\")]}\n",
    "\n",
    "# ë™ê¸° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬(stream_mode=\"values\")\n",
    "for chunk in graph.stream(inputs, stream_mode=\"values\"):\n",
    "\n",
    "    # chunk ëŠ” dictionary í˜•íƒœ(key: State ì˜ key, value: State ì˜ value)\n",
    "    for state_key, state_value in chunk.items():\n",
    "        if state_key == \"messages\":\n",
    "            state_value[-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ë‹¨ìˆœ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_keyword (call_AyqpG130hYfN8fM3kjyuOQ3H)\n",
      " Call ID: call_AyqpG130hYfN8fM3kjyuOQ3H\n",
      "  Args:\n",
      "    query: AI\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_keyword\n",
      "\n",
      "- \"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì • - AIíƒ€ì„ìŠ¤\n",
      "- AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™ - í•œê²¨ë ˆ\n",
      "- [ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\" - ì¡°ì„ ì¼ë³´\n",
      "- ë„¤ì´ë²„, AI ìƒìš©í™” ë°©ì•ˆ ê³µê°œâ€¦\"ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤\" - SBS ë‰´ìŠ¤\n",
      "- íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì› - ë””ì§€í„¸íˆ¬ë°ì´\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ë‹¤ìŒì€ AI ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **\"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì •** - AIíƒ€ì„ìŠ¤\n",
      "2. **AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™** - í•œê²¨ë ˆ\n",
      "3. **[ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\"** - ì¡°ì„ ì¼ë³´\n",
      "4. **ë„¤ì´ë²„, AI ìƒìš©í™” ë°©ì•ˆ ê³µê°œâ€¦\"ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤\"** - SBS ë‰´ìŠ¤\n",
      "5. **íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì›** - ë””ì§€í„¸íˆ¬ë°ì´\n",
      "\n",
      "ë” ê¶ê¸ˆí•œ ë‚´ìš©ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\"messages\": [(\"human\", \"AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\")]}\n",
    "\n",
    "# ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬(stream_mode=\"values\")\n",
    "async for chunk in graph.astream(inputs, stream_mode=\"values\"):\n",
    "    # chunk ëŠ” dictionary í˜•íƒœ(key: State ì˜ key, value: State ì˜ value)\n",
    "    for state_key, state_value in chunk.items():\n",
    "        if state_key == \"messages\":\n",
    "            state_value[-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ìŠ¤íŠ¸ë¦¬ë° ìµœì¢… ê²°ê³¼ë§Œ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì‹  AI ê´€ë ¨ ë‰´ìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **\"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì •** - AIíƒ€ì„ìŠ¤\n",
      "2. **AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™** - í•œê²¨ë ˆ\n",
      "3. **[ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\"** - ì¡°ì„ ì¼ë³´\n",
      "4. **ë„¤ì´ë²„, AI ìƒìš©í™” ë°©ì•ˆ ê³µê°œâ€¦\"ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤\"** - SBS ë‰´ìŠ¤\n",
      "5. **íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì›** - ë””ì§€í„¸íˆ¬ë°ì´\n",
      "\n",
      "ì´ ë‰´ìŠ¤ë“¤ì€ AI ê¸°ìˆ ì˜ ë°œì „, ìƒìš©í™”, ê·¸ë¦¬ê³  ê´€ë ¨ ì‚°ì—…ì˜ ë³€í™”ì— ëŒ€í•´ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\"messages\": [(\"human\", \"AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\")]}\n",
    "\n",
    "final_result = None\n",
    "\n",
    "# ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬(stream_mode=\"values\")\n",
    "async for chunk in graph.astream(inputs, stream_mode=\"values\"):\n",
    "    final_result = chunk\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "print(final_result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stream modeê°€ updates ë©´ì€ ìƒˆë¡œ ìƒê¸´ ìƒíƒœë§Œ ì¶œë ¥ì´ ëœë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Node: chatbot]\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_keyword (call_thF1FKThIhw5X1AUxVRZeP7z)\n",
      " Call ID: call_thF1FKThIhw5X1AUxVRZeP7z\n",
      "  Args:\n",
      "    query: AI\n",
      "\n",
      "[Node: tools]\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_keyword\n",
      "\n",
      "- \"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì • - AIíƒ€ì„ìŠ¤\n",
      "- AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™ - í•œê²¨ë ˆ\n",
      "- [ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\" - ì¡°ì„ ì¼ë³´\n",
      "- ë„¤ì´ë²„, í†µí•© ì½˜í¼ëŸ°ìŠ¤ DAN 24 ê°œìµœâ€¦'AI ì›ì²œê¸°ìˆ  ë°€ì°©' ì„ ì–¸ - ì „ìì‹ ë¬¸\n",
      "- íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì› - ë””ì§€í„¸íˆ¬ë°ì´\n",
      "\n",
      "[Node: chatbot]\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ë‹¤ìŒì€ AI ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **\"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì •** - AIíƒ€ì„ìŠ¤\n",
      "2. **AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™** - í•œê²¨ë ˆ\n",
      "3. **[ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\"** - ì¡°ì„ ì¼ë³´\n",
      "4. **ë„¤ì´ë²„, í†µí•© ì½˜í¼ëŸ°ìŠ¤ DAN 24 ê°œìµœâ€¦'AI ì›ì²œê¸°ìˆ  ë°€ì°©' ì„ ì–¸** - ì „ìì‹ ë¬¸\n",
      "5. **íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì›** - ë””ì§€í„¸íˆ¬ë°ì´\n",
      "\n",
      "ì´ë“¤ ë‰´ìŠ¤ëŠ” AI ë¶„ì•¼ì˜ ë‹¤ì–‘í•œ ìµœì‹  ë™í–¥ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [(\"human\", \"AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\")]}\n",
    "\n",
    "# ë™ê¸° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬(stream_mode=\"updates\")\n",
    "for chunk in graph.stream(inputs, stream_mode=\"updates\"):\n",
    "    # chunk ëŠ” dictionary í˜•íƒœ(key: ë…¸ë“œ, value: ë…¸ë“œì˜ ìƒíƒœ ê°’)\n",
    "    for node, value in chunk.items():\n",
    "        if node:\n",
    "            print(f\"\\n[Node: {node}]\\n\")\n",
    "        if \"messages\" in value:\n",
    "            value[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "messagesëŠ” ê° ë‹¨ê³„ ë©”ì‹œì§€ë§Œ ì¶œë ¥í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- \"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì • - AIíƒ€ì„ìŠ¤\n",
      "- AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™ - í•œê²¨ë ˆ\n",
      "- [ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\" - ì¡°ì„ ì¼ë³´\n",
      "- ë„¤ì´ë²„, í†µí•© ì½˜í¼ëŸ°ìŠ¤ DAN 24 ê°œìµœâ€¦'AI ì›ì²œê¸°ìˆ  ë°€ì°©' ì„ ì–¸ - ì „ìì‹ ë¬¸\n",
      "- íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì› - ë””ì§€í„¸íˆ¬ë°ì´\n",
      "\n",
      "\n",
      "metadata: \n",
      "{'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ['branch:chatbot:tools_condition:tools'], 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:7712b7ff-5b40-d847-7bf2-56a960db427c'}\n",
      "\n",
      "\n",
      "ìµœê·¼ AI ê´€ë ¨ ë‰´ìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **\"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì •** - AIíƒ€ì„ìŠ¤\n",
      "2. **AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™** - í•œê²¨ë ˆ\n",
      "3. **[ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\"** - ì¡°ì„ ì¼ë³´\n",
      "4. **ë„¤ì´ë²„, í†µí•© ì½˜í¼ëŸ°ìŠ¤ DAN 24 ê°œìµœâ€¦'AI ì›ì²œê¸°ìˆ  ë°€ì°©' ì„ ì–¸** - ì „ìì‹ ë¬¸\n",
      "5. **íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì›** - ë””ì§€í„¸íˆ¬ë°ì´\n",
      "\n",
      "ë” ê¶ê¸ˆí•œ ë‚´ìš©ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\"messages\": [(\"human\", \"AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\")]}\n",
    "\n",
    "# ë™ê¸° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬(stream_mode=\"messages\")\n",
    "# chunk_msg: ì‹¤ì‹œê°„ ì¶œë ¥ ë©”ì‹œì§€, metadata: ë…¸ë“œ ì •ë³´\n",
    "for chunk_msg, metadata  in graph.stream(inputs, stream_mode=\"messages\"):\n",
    "\n",
    "    # chatbot ë…¸ë“œì—ì„œ ì¶œë ¥ëœ ë©”ì‹œì§€ë§Œ ì¶œë ¥\n",
    "    if metadata[\"langgraph_node\"] == \"chatbot\":\n",
    "        if chunk_msg.content:\n",
    "            print(chunk_msg.content, end=\"\", flush=True)\n",
    "\n",
    "    else:\n",
    "        print(chunk_msg.content)\n",
    "        print(f\"\\n\\nmetadata: \\n{metadata}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íƒœê·¸ ì‚¬ìš© ë°©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "########## 1. ìƒíƒœ ì •ì˜ ##########\n",
    "# ìƒíƒœ ì •ì˜\n",
    "class State(TypedDict):\n",
    "    # ë©”ì‹œì§€ ëª©ë¡ ì£¼ì„ ì¶”ê°€\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "########## 2. ë„êµ¬ ì •ì˜ ë° ë°”ì¸ë”© ##########\n",
    "# ë„êµ¬ ì´ˆê¸°í™”\n",
    "# í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ ìƒì„±\n",
    "@tool\n",
    "def search_keyword(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Look up news by keyword\"\"\"\n",
    "    news_tool = GoogleNews()\n",
    "    return \"\\n\".join([f'- {news[\"content\"]}' for news in news_tool.search_by_keyword(query, k=5)])\n",
    "\n",
    "\n",
    "# ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "tools = [search_keyword]\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# ë„êµ¬ì™€ LLM ê²°í•© (tags ì¶”ê°€)\n",
    "llm_with_tools = llm.bind_tools(tools).with_config(tags=[\"WANT_TO_STREAM\"])\n",
    "\n",
    "########## 3. ë…¸ë“œ ì¶”ê°€ ##########\n",
    "# ì±—ë´‡ í•¨ìˆ˜ ì •ì˜\n",
    "def chatbot(state: State):\n",
    "    # ë©”ì‹œì§€ í˜¸ì¶œ ë° ë°˜í™˜\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# ìƒíƒœ ê·¸ë˜í”„ ìƒì„±\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# ì±—ë´‡ ë…¸ë“œ ì¶”ê°€\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# ë„êµ¬ ë…¸ë“œ ìƒì„± ë° ì¶”ê°€\n",
    "tool_node = ToolNode(tools=[search_keyword])\n",
    "\n",
    "# ë„êµ¬ ë…¸ë“œ ì¶”ê°€\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "########## 4. ì—£ì§€ ì¶”ê°€ ##########\n",
    "\n",
    "# tools > chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# START > chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# chatbot > END\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\"messages\": [(\"human\", \"AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\")]}\n",
    "\n",
    "# ë¹„ë™ê¸° ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬(astream_events)\n",
    "async for event in graph.astream_events(inputs, version=\"v2\"):\n",
    "    # ì´ë²¤íŠ¸ ì¢…ë¥˜ì™€ íƒœê·¸ ì •ë³´ ì¶”ì¶œ\n",
    "    kind = event[\"event\"]\n",
    "    tags = event.get(\"tags\", [])\n",
    "    print(event)\n",
    "    # ì±„íŒ… ëª¨ë¸ ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸ ë° ìµœì¢… ë…¸ë“œ íƒœê·¸ í•„í„°ë§\n",
    "    if kind == \"on_chat_model_stream\" and \"WANT_TO_STREAM\" in tags:\n",
    "        # ì´ë²¤íŠ¸ ë°ì´í„° ì¶”ì¶œ\n",
    "        data = event[\"data\"]\n",
    "\n",
    "        # ì¶œë ¥ ë©”ì‹œì§€\n",
    "        if data[\"chunk\"].content:\n",
    "            print(data[\"chunk\"].content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{'query': ''}\n",
      "{'query': 'AI'}\n",
      "{'query': 'AI'}\n",
      "- \"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì • - AIíƒ€ì„ìŠ¤\n",
      "- AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™ - í•œê²¨ë ˆ\n",
      "- [ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\" - ì¡°ì„ ì¼ë³´\n",
      "- ë„¤ì´ë²„, AI ìƒìš©í™” ë°©ì•ˆ ê³µê°œâ€¦\"ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤\" - SBS ë‰´ìŠ¤\n",
      "- íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì› - ë””ì§€í„¸íˆ¬ë°ì´ë‹¤ìŒì€ AI ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **\"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì •** - AIíƒ€ì„ìŠ¤\n",
      "2. **AI êµê³¼ì„œ â€˜ììœ¨â€™â†’â€˜ì—„ê²© ê²€ì •â€™ ëŒë³€â€¦ì¶œíŒì‚¬ë“¤ â€˜ì¡¸ì† í›„í­í’â€™** - í•œê²¨ë ˆ\n",
      "3. **[ì«Œì•„ëŠ”ê¸°ìë“¤] SBVA ì´ì¤€í‘œì˜ AIë¡ , \"ëŒ€ì „ì˜ ìŠ¤íƒ ë‹¤ë“œì—ë„ˆì§€ëŠ” ê²Œì„ì²´ì¸ì €ê°€ ë  ìˆ˜ë„ ìˆë‹¤\"** - ì¡°ì„ ì¼ë³´\n",
      "4. **ë„¤ì´ë²„, AI ìƒìš©í™” ë°©ì•ˆ ê³µê°œâ€¦\"ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤\"** - SBS ë‰´ìŠ¤\n",
      "5. **íŒŒì¸ë”ìŠ¤ì—ì´ì•„ì´, â€˜AI ìë™ ê³„ì‚°ëŒ€â€™ ê³µê°œ...1ì´ˆ ì•ˆì— ìƒí’ˆ ê°ì§€Â·ê²°ì œ ì§€ì›** - ë””ì§€í„¸íˆ¬ë°ì´\n",
      "\n",
      "ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessageChunk, HumanMessage\n",
    "\n",
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\"messages\": [(\"human\", \"AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\")]}\n",
    "\n",
    "# ì²« ë²ˆì§¸ ë©”ì‹œì§€ ì²˜ë¦¬ ì—¬ë¶€ í”Œë˜ê·¸ ì„¤ì •\n",
    "first = True\n",
    "\n",
    "# ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ë¥¼ í†µí•œ ë©”ì‹œì§€ ë° ë©”íƒ€ë°ì´í„° ìˆœì°¨ ì²˜ë¦¬\n",
    "for msg, metadata in graph.stream(inputs, stream_mode=\"messages\"):\n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš°ì˜ ì»¨í…ì¸  ì¶œë ¥ ì²˜ë¦¬\n",
    "    if msg.content and not isinstance(msg, HumanMessage):\n",
    "        print(msg.content, end=\"\", flush=True)\n",
    "\n",
    "    # AI ë©”ì‹œì§€ ì²­í¬ ì²˜ë¦¬ ë° ëˆ„ì \n",
    "    if isinstance(msg, AIMessageChunk):\n",
    "        if first:\n",
    "            gathered = msg\n",
    "            first = False\n",
    "        else:\n",
    "            gathered = gathered + msg\n",
    "\n",
    "        # ë„êµ¬ í˜¸ì¶œ ì²­í¬ ì¡´ì¬ ì‹œ ëˆ„ì ëœ ë„êµ¬ í˜¸ì¶œ ì •ë³´ ì¶œë ¥\n",
    "        if msg.tool_call_chunks:\n",
    "            print(gathered.tool_calls[0][\"args\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì—¬ëŸ¬ ê·¸ë˜í”„ í•©ì³¤ì„ ë•Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "########## 1. ìƒíƒœ ì •ì˜ ##########\n",
    "# ìƒíƒœ ì •ì˜\n",
    "class State(TypedDict):\n",
    "    # ë©”ì‹œì§€ ëª©ë¡ ì£¼ì„ ì¶”ê°€\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "########## 2. ë„êµ¬ ì •ì˜ ë° ë°”ì¸ë”© ##########\n",
    "# ë„êµ¬ ì´ˆê¸°í™”\n",
    "# í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ ìƒì„±\n",
    "@tool\n",
    "def search_keyword(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Look up news by keyword\"\"\"\n",
    "    news_tool = GoogleNews()\n",
    "    return \"\\n\".join([f'- {news[\"content\"]}' for news in news_tool.search_by_keyword(query, k=5)])\n",
    "\n",
    "\n",
    "# ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "tools = [search_keyword]\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# ë„êµ¬ì™€ LLM ê²°í•© (tags ì¶”ê°€)\n",
    "llm_with_tools = llm.bind_tools(tools).with_config(tags=[\"WANT_TO_STREAM\"])\n",
    "\n",
    "########## 3. ë…¸ë“œ ì¶”ê°€ ##########\n",
    "# ì±—ë´‡ í•¨ìˆ˜ ì •ì˜\n",
    "def chatbot(state: State):\n",
    "    # ë©”ì‹œì§€ í˜¸ì¶œ ë° ë°˜í™˜\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# SNS í¬ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ ì •ì˜\n",
    "def create_sns_post(state: State):\n",
    "    # SNS í¬ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸\n",
    "    sns_prompt = \"\"\"\n",
    "    ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ SNS ê²Œì‹œê¸€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.\n",
    "    ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”:\n",
    "    - í•´ì‹œíƒœê·¸ í¬í•¨\n",
    "    - ì´ëª¨ì§€ ì‚¬ìš©\n",
    "    - ê°„ê²°í•˜ê³  í¥ë¯¸ë¡œìš´ ë¬¸ì²´ ì‚¬ìš©\n",
    "    - 200ì ì´ë‚´ë¡œ ì‘ì„±\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"] + [(\"human\", sns_prompt)]\n",
    "    sns_llm = ChatOpenAI(model=\"gpt-4o-mini\").with_config(tags=[\"WANT_TO_STREAM2\"])\n",
    "    return {\"messages\": [sns_llm.invoke(messages)]}\n",
    "\n",
    "# ì„œë¸Œê·¸ë˜í”„ ìƒì„±\n",
    "def create_subgraph():\n",
    "    # ì„œë¸Œê·¸ë˜í”„ìš© ìƒíƒœ ê·¸ë˜í”„ ìƒì„± \n",
    "    subgraph = StateGraph(State)\n",
    "\n",
    "    # ì±—ë´‡ ë…¸ë“œ ì¶”ê°€\n",
    "    subgraph.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "    # ë„êµ¬ ë…¸ë“œ ìƒì„± ë° ì¶”ê°€\n",
    "    tool_node = ToolNode(tools=[search_keyword])\n",
    "    subgraph.add_node(\"tools\", tool_node)\n",
    "\n",
    "    # ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€\n",
    "    subgraph.add_conditional_edges(\n",
    "        \"chatbot\",\n",
    "        tools_condition,\n",
    "    )\n",
    "\n",
    "    # tools > chatbot\n",
    "    subgraph.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "    # START > chatbot\n",
    "    subgraph.add_edge(START, \"chatbot\")\n",
    "\n",
    "    # chatbot > END \n",
    "    subgraph.add_edge(\"chatbot\", END)\n",
    "\n",
    "    return subgraph.compile()\n",
    "\n",
    "# ë©”ì¸ ê·¸ë˜í”„ ìƒì„±\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# ì„œë¸Œê·¸ë˜í”„ ì¶”ê°€\n",
    "subgraph = create_subgraph()\n",
    "graph_builder.add_node(\"news_subgraph\", subgraph)\n",
    "\n",
    "# SNS í¬ìŠ¤íŠ¸ ìƒì„± ë…¸ë“œ ì¶”ê°€\n",
    "graph_builder.add_node(\"sns_post\", create_sns_post)\n",
    "\n",
    "# START > news_subgraph\n",
    "graph_builder.add_edge(START, \"news_subgraph\")\n",
    "\n",
    "# news_subgraph > sns_post\n",
    "graph_builder.add_edge(\"news_subgraph\", \"sns_post\")\n",
    "\n",
    "# sns_post > END\n",
    "graph_builder.add_edge(\"sns_post\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì„œë¸Œ ê·¸ë˜í”„ ì¶œë ¥ì€ í¬í•¨ë˜ì§€ ì•ŠìŒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Update from node news_subgraph =========\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ìµœê·¼ AI ê´€ë ¨ ë‰´ìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **\"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì •** - AIíƒ€ì„ìŠ¤\n",
      "2. **\"ì¸ê°„ ë„˜ì–´ì„œëŠ” AI, ê²½ì œì  ê°€ì¹˜ 1ê²½ë‹¬ëŸ¬â€¦ê°•ë ¥í•œ ë§Œí¼ ìœ„í—˜\"** - í•œêµ­ê²½ì œ\n",
      "3. **ë„¤ì´ë²„, ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤â€¥\"AI ì›ì²œê¸°ìˆ  ë°€ì°© ì„ ì–¸\"** - MBC ë‰´ìŠ¤\n",
      "4. **ì¤‘êµ­ ë¹…í…Œí¬, AI ì¸ë ¥ í™•ë³´ ì „ìŸâ€¦\"IT í‰ê· ì˜ 2ë°° ê¸‰ì—¬ë¡œ êµ¬ì• \"** - ì—°í•©ë‰´ìŠ¤\n",
      "5. **AIìŠ¤ë§ˆíŠ¸ê´‘ìœµë³µí•©í˜‘ë™ì¡°í•©, ê´‘ì£¼êµ­ì œê³  AIoTì‹¤í—˜ ê³¼í•™íŠ¹ê°• ì„±ë£Œ** - ì „ê¸°ì‹ ë¬¸\n",
      "\n",
      "ë” ê¶ê¸ˆí•œ ë‚´ìš©ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "\n",
      "========= Update from node sns_post =========\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ğŸš€ ìµœì‹  AI ë‰´ìŠ¤! ğŸ¤–\n",
      "\n",
      "ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì • ì¤‘! ğŸ’¡ ì¸ê°„ì„ ë„˜ì–´ì„œëŠ” AIì˜ ê²½ì œì  ê°€ì¹˜ëŠ” ë¬´ë ¤ 1ê²½ ë‹¬ëŸ¬! ğŸ’° ë„¤ì´ë²„ëŠ” ë‚´ë…„ AI ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì¶œì‹œ ì˜ˆì •! ğŸ” ì¤‘êµ­ ë¹…í…Œí¬ëŠ” AI ì¸ë ¥ í™•ë³´ ì „ìŸ ì¤‘! ğŸ¥‡\n",
      "\n",
      "#AI #ì¸ê³µì§€ëŠ¥ #ì˜¤í”ˆAI #ë„¤ì´ë²„ #ê¸°ìˆ í˜ì‹  #ê²½ì œ #íŠ¸ë Œë“œ\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\"messages\": [(\"human\", \"AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\")]}\n",
    "\n",
    "# ë…¸ë“œ ì—…ë°ì´íŠ¸ ì •ë³´ ìˆœì°¨ì  ì²˜ë¦¬ ë° ì¶œë ¥\n",
    "for chunk in graph.stream(inputs, stream_mode=\"updates\"):\n",
    "    # node_name: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë…¸ë“œëª…, node_chunk: í•´ë‹¹ ë…¸ë“œì˜ ì²­í¬ ë°ì´í„°\n",
    "    for node_name, node_chunk in chunk.items():\n",
    "        # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë…¸ë“œ êµ¬ë¶„ì„  ì¶œë ¥\n",
    "        print(f\"\\n========= Update from node {node_name} =========\\n\")\n",
    "        # í•´ë‹¹ ë…¸ë“œì˜ ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì¶œë ¥\n",
    "        if \"messages\" in node_chunk:\n",
    "            node_chunk[\"messages\"][-1].pretty_print()\n",
    "        else:\n",
    "            print(node_chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§Œì•½ ì„œë¸Œ ê·¸ë˜í”„ ì¶œë ¥ë„ í•„ìš”í•˜ë‹¤ë©´ subgraphs íŒŒë¼ë¯¸í„°ë¥¼ Trueë¡œ ë„£ì–´ì•¼í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Update from node [chatbot] in [news_subgraph] =========\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_keyword (call_WytvAshylxBbOvX9phT0pUDl)\n",
      " Call ID: call_WytvAshylxBbOvX9phT0pUDl\n",
      "  Args:\n",
      "    query: AI\n",
      "\n",
      "========= Update from node [tools] in [news_subgraph] =========\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_keyword\n",
      "\n",
      "- \"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì • - AIíƒ€ì„ìŠ¤\n",
      "- \"ì¸ê°„ ë„˜ì–´ì„œëŠ” AI, ê²½ì œì  ê°€ì¹˜ 1ê²½ë‹¬ëŸ¬â€¦ê°•ë ¥í•œ ë§Œí¼ ìœ„í—˜\" - í•œêµ­ê²½ì œ\n",
      "- ë„¤ì´ë²„, ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤â€¥\"AI ì›ì²œê¸°ìˆ  ë°€ì°© ì„ ì–¸\" - MBC ë‰´ìŠ¤\n",
      "- ì¤‘êµ­ ë¹…í…Œí¬, AI ì¸ë ¥ í™•ë³´ ì „ìŸâ€¦\"IT í‰ê· ì˜ 2ë°° ê¸‰ì—¬ë¡œ êµ¬ì• \" - ì—°í•©ë‰´ìŠ¤\n",
      "- AIìŠ¤ë§ˆíŠ¸ê´‘ìœµë³µí•©í˜‘ë™ì¡°í•©, ê´‘ì£¼êµ­ì œê³  AIoTì‹¤í—˜ ê³¼í•™íŠ¹ê°• ì„±ë£Œ - ì „ê¸°ì‹ ë¬¸\n",
      "\n",
      "========= Update from node [chatbot] in [news_subgraph] =========\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ë‹¤ìŒì€ AI ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **\"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì •** - AIíƒ€ì„ìŠ¤\n",
      "2. **\"ì¸ê°„ ë„˜ì–´ì„œëŠ” AI, ê²½ì œì  ê°€ì¹˜ 1ê²½ë‹¬ëŸ¬â€¦ê°•ë ¥í•œ ë§Œí¼ ìœ„í—˜\"** - í•œêµ­ê²½ì œ\n",
      "3. **ë„¤ì´ë²„, ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤â€¥\"AI ì›ì²œê¸°ìˆ  ë°€ì°© ì„ ì–¸\"** - MBC ë‰´ìŠ¤\n",
      "4. **ì¤‘êµ­ ë¹…í…Œí¬, AI ì¸ë ¥ í™•ë³´ ì „ìŸâ€¦\"IT í‰ê· ì˜ 2ë°° ê¸‰ì—¬ë¡œ êµ¬ì• \"** - ì—°í•©ë‰´ìŠ¤\n",
      "5. **AIìŠ¤ë§ˆíŠ¸ê´‘ìœµë³µí•©í˜‘ë™ì¡°í•©, ê´‘ì£¼êµ­ì œê³  AIoTì‹¤í—˜ ê³¼í•™íŠ¹ê°• ì„±ë£Œ** - ì „ê¸°ì‹ ë¬¸\n",
      "\n",
      "ë” ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "\n",
      "========= Update from node [news_subgraph] in [parent graph] =========\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ë‹¤ìŒì€ AI ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **\"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì •** - AIíƒ€ì„ìŠ¤\n",
      "2. **\"ì¸ê°„ ë„˜ì–´ì„œëŠ” AI, ê²½ì œì  ê°€ì¹˜ 1ê²½ë‹¬ëŸ¬â€¦ê°•ë ¥í•œ ë§Œí¼ ìœ„í—˜\"** - í•œêµ­ê²½ì œ\n",
      "3. **ë„¤ì´ë²„, ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤â€¥\"AI ì›ì²œê¸°ìˆ  ë°€ì°© ì„ ì–¸\"** - MBC ë‰´ìŠ¤\n",
      "4. **ì¤‘êµ­ ë¹…í…Œí¬, AI ì¸ë ¥ í™•ë³´ ì „ìŸâ€¦\"IT í‰ê· ì˜ 2ë°° ê¸‰ì—¬ë¡œ êµ¬ì• \"** - ì—°í•©ë‰´ìŠ¤\n",
      "5. **AIìŠ¤ë§ˆíŠ¸ê´‘ìœµë³µí•©í˜‘ë™ì¡°í•©, ê´‘ì£¼êµ­ì œê³  AIoTì‹¤í—˜ ê³¼í•™íŠ¹ê°• ì„±ë£Œ** - ì „ê¸°ì‹ ë¬¸\n",
      "\n",
      "ë” ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "\n",
      "========= Update from node [sns_post] in [parent graph] =========\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ğŸš€ ìµœì‹  AI ì†Œì‹! ğŸ¤–\n",
      "\n",
      "ì˜¤í”ˆAI, GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”ë¡œ ì „ëµ ìˆ˜ì •! ğŸ’¡ ê²½ì œì  ê°€ì¹˜ 1ê²½ ë‹¬ëŸ¬ì˜ AI, ê°•ë ¥í•˜ì§€ë§Œ ìœ„í—˜ë„ í¬ë‹¤ë‹ˆ! âš ï¸ ë„¤ì´ë²„ëŠ” ë‚´ë…„ AI ê²€ìƒ‰ ì„œë¹„ìŠ¤ ë¡ ì¹­ ì˜ˆì •! ğŸ”\n",
      "\n",
      "#AI #ì˜¤í”ˆAI #ë„¤ì´ë²„ #ê¸°ìˆ í˜ì‹  #ë¯¸ë˜ê¸°ìˆ  #ì¸ê³µì§€ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì…ë ¥ ë°ì´í„° êµ¬ì„±\n",
    "inputs = {\"messages\": [(\"human\", \"AI ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì¤˜\")]}\n",
    "\n",
    "# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¬¸ìì—´ì„ ë³´ê¸° ì¢‹ì€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í¬ë§·íŒ… í•¨ìˆ˜\n",
    "def format_namespace(namespace):\n",
    "    return (\n",
    "        namespace[-1].split(\":\")[0]\n",
    "        if len(namespace) > 0\n",
    "        else \"parent graph\"\n",
    "    )\n",
    "\n",
    "# subgraphs=True ë¥¼ í†µí•´ ì„œë¸Œê·¸ë˜í”„ì˜ ì¶œë ¥ë„ í¬í•¨(namespace, chunk) í˜•íƒœë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.\n",
    "for namespace, chunk in graph.stream(inputs, stream_mode=\"updates\", subgraphs=True):\n",
    "    # node_name: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë…¸ë“œëª…, node_chunk: í•´ë‹¹ ë…¸ë“œì˜ ì²­í¬ ë°ì´í„°\n",
    "    for node_name, node_chunk in chunk.items():\n",
    "        print(f\"\\n========= Update from node [{node_name}] in [{format_namespace(namespace)}] =========\\n\")\n",
    "\n",
    "        # ë…¸ë“œì˜ ì²­í¬ ë°ì´í„° ì¶œë ¥\n",
    "        if \"messages\" in node_chunk:\n",
    "            node_chunk[\"messages\"][-1].pretty_print()\n",
    "        else:\n",
    "            print(node_chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "event íƒ€ì…ë³„ë¡œ ì •ë¦¬í•  ìˆ˜ë„ ìˆìŒ.\n",
    "\n",
    "ì¡´ì¬í•˜ëŠ” íƒ€ì… ì˜ˆì‹œëŠ” : https://wikidocs.net/265576 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= tool_start =========\n",
      "\n",
      "{'query': 'AI'}\n",
      "\n",
      "========= tool_end =========\n",
      "\n",
      "- \"GPT ì„±ëŠ¥ í–¥ìƒ ì†ë„ ë‘”í™”\"...ì˜¤í”ˆAI, 'ì˜¤ë¼ì´ì˜¨' ê°œì„  ìœ„í•´ ì „ëµ ìˆ˜ì • - AIíƒ€ì„ìŠ¤\n",
      "- \"ì¸ê°„ ë„˜ì–´ì„œëŠ” AI, ê²½ì œì  ê°€ì¹˜ 1ê²½ë‹¬ëŸ¬â€¦ê°•ë ¥í•œ ë§Œí¼ ìœ„í—˜\" - í•œêµ­ê²½ì œ\n",
      "- ë„¤ì´ë²„, ë‚´ë…„ ìƒë°˜ê¸° AI ê²€ìƒ‰ ì„œë¹„ìŠ¤â€¥\"AI ì›ì²œê¸°ìˆ  ë°€ì°© ì„ ì–¸\" - MBC ë‰´ìŠ¤\n",
      "- ì¤‘êµ­ ë¹…í…Œí¬, AI ì¸ë ¥ í™•ë³´ ì „ìŸâ€¦\"IT í‰ê· ì˜ 2ë°° ê¸‰ì—¬ë¡œ êµ¬ì• \" - ì—°í•©ë‰´ìŠ¤\n",
      "- AIìŠ¤ë§ˆíŠ¸ê´‘ìœµë³µí•©í˜‘ë™ì¡°í•©, ê´‘ì£¼êµ­ì œê³  AIoTì‹¤í—˜ ê³¼í•™íŠ¹ê°• ì„±ë£Œ - ì „ê¸°ì‹ ë¬¸\n"
     ]
    }
   ],
   "source": [
    "# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ë³´ë¥¼ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜\n",
    "def parse_namespace_info(info: tuple) -> tuple[str, str]:\n",
    "    if len(info) > 1:\n",
    "        namespace, node_name = info\n",
    "        return node_name.split(\":\")[0], namespace.split(\":\")[0]\n",
    "    return info[0].split(\":\")[0], \"parent graph\"\n",
    "\n",
    "kind = None\n",
    "\n",
    "async for event in graph.astream_events(inputs, version=\"v2\", subgraphs=True):\n",
    "    kind = event[\"event\"]\n",
    "\n",
    "    # ì´ë²¤íŠ¸ ì¢…ë¥˜ì™€ íƒœê·¸ ì •ë³´ ì¶”ì¶œ\n",
    "    if kind == \"on_chat_model_start\":\n",
    "        print(f\"\\n========= on_chat_model_start =========\\n\")\n",
    "\n",
    "    # ì±„íŒ… ëª¨ë¸ ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸ ë° ìµœì¢… ë…¸ë“œ íƒœê·¸ í•„í„°ë§\n",
    "    elif kind == \"on_chat_model_stream\":\n",
    "        # ì´ë²¤íŠ¸ ë°ì´í„° ì¶”ì¶œ\n",
    "        data = event[\"data\"]\n",
    "\n",
    "        # í† í° ë‹¨ìœ„ì˜ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "        if data[\"chunk\"].content:\n",
    "            print(data[\"chunk\"].content, end=\"\", flush=True)\n",
    "\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(f\"\\n========= tool_start =========\\n\")\n",
    "        data = event[\"data\"]\n",
    "        if \"input\" in data:\n",
    "            tool_msg = data[\"input\"]\n",
    "            print(tool_msg)            \n",
    "\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"\\n========= tool_end =========\\n\")\n",
    "        data = event[\"data\"]\n",
    "        if \"output\" in data:\n",
    "            tool_msg = data[\"output\"]\n",
    "            print(tool_msg.content)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
