{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대화 요약 기능 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구조\n",
    "\n",
    "ask_llm : 요약 메시지가 있으면 요약까지 포함해서 답을 하고 아니면 그냥 답만 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Literal, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, RemoveMessage, HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 메모리 저장소 설정\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "# 메시지 상태와 요약 정보를 포함하는 상태 클래스\n",
    "class State(MessagesState):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    summary: str\n",
    "\n",
    "\n",
    "# 대화 및 요약을 위한 모델 초기화\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "def ask_llm(state: State):\n",
    "    # 이전 요약 정보 확인\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # 이전 요약 정보가 있다면 시스템 메시지로 추가\n",
    "    if summary:\n",
    "        # 시스템 메시지 생성\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "        # 시스템 메시지와 이전 메시지 결합\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    else:\n",
    "        # 이전 메시지만 사용\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    # 모델 호출\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # 응답 반환\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should_condition : 메시지가 6개 넘게 쌓였으면 요약 노드로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "\n",
    "# 대화 종료 또는 요약 결정 로직\n",
    "def should_continue(state: State) -> Literal[\"summarize_conversation\", END]:\n",
    "    # 메시지 목록 확인\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 메시지 수가 6개 초과라면 요약 노드로 이동\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약 노드는 이전에 summary가 있으면 그걸 반영하서 summary를 업데이트 시키고 만약 없었다면 처음으로 summary를 만들고 message는 삭제된 메시지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 내용 요약 및 메시지 정리 로직\n",
    "def summarize_conversation(state: State):\n",
    "    # 이전 요약 정보 확인\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # 이전 요약 정보가 있다면 요약 메시지 생성\n",
    "    if summary:\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above in Korean:\"\n",
    "        )\n",
    "    else:\n",
    "        # 요약 메시지 생성\n",
    "        summary_message = \"Create a summary of the conversation above in Korean:\"\n",
    "\n",
    "    # 요약 메시지와 이전 메시지 결합\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    # 모델 호출\n",
    "    response = model.invoke(messages)\n",
    "    # 오래된 메시지 삭제\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    # 요약 정보 반환\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 그래프 초기화\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 대화 및 요약 노드 추가\n",
    "workflow.add_node(\"conversation\", ask_llm)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# 시작점을 대화 노드로 설정\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "\n",
    "# 조건부 엣지 추가\n",
    "workflow.add_conditional_edges(\n",
    "    \"conversation\",\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# 요약 노드에서 종료 노드로의 엣지 추가\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# 워크플로우 컴파일 및 메모리 체크포인터 설정\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화 요약 했는지 확인 하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업데이트 정보 출력 함수\n",
    "def print_update(update):\n",
    "    # 업데이트 딕셔너리 순회\n",
    "    for k, v in update.items():\n",
    "        # 메시지 목록 출력\n",
    "        for m in v[\"messages\"]:\n",
    "            m.pretty_print()\n",
    "        # 요약 정보 존재 시 출력\n",
    "        if \"summary\" in v:\n",
    "            print(v[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화 요약 안 한 것을 볼 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "안녕하세요? 반갑습니다. 제 이름은 테디입니다.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요, 테디님! 반갑습니다. 어떻게 도와드릴까요?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "제 이름이 뭔지 기억하세요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "네, 테디님이라고 하셨습니다! 어떻게 도와드릴까요?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "제 직업은 AI 연구원이에요\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "멋진 직업이네요, 테디님! AI 연구원으로서 어떤 분야에 주로 관심이 있으신가요? 또는 현재 진행 중인 프로젝트가 있으신가요?\n"
     ]
    }
   ],
   "source": [
    "# 메시지 핸들링을 위한 HumanMessage 클래스 임포트\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 스레드 ID가 포함된 설정 객체 초기화\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# 첫 번째 사용자 메시지 생성 및 출력\n",
    "input_message = HumanMessage(content=\"안녕하세요? 반갑습니다. 제 이름은 테디입니다.\")\n",
    "input_message.pretty_print()\n",
    "\n",
    "# 스트림 모드에서 첫 번째 메시지 처리 및 업데이트 출력\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)\n",
    "\n",
    "# 두 번째 사용자 메시지 생성 및 출력\n",
    "input_message = HumanMessage(content=\"제 이름이 뭔지 기억하세요?\")\n",
    "input_message.pretty_print()\n",
    "\n",
    "# 스트림 모드에서 두 번째 메시지 처리 및 업데이트 출력\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)\n",
    "\n",
    "# 세 번째 사용자 메시지 생성 및 출력\n",
    "input_message = HumanMessage(content=\"제 직업은 AI 연구원이에요\")\n",
    "input_message.pretty_print()\n",
    "\n",
    "# 스트림 모드에서 세 번째 메시지 처리 및 업데이트 출력\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6개 이상 되는 순간 대화 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "최근 LLM 에 대해 좀 더 알아보고 있어요. LLM 에 대한 최근 논문을 읽고 있습니다.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LLM(대규모 언어 모델)에 대한 연구는 정말 흥미로운 분야입니다! 최근 몇 년 동안 많은 발전이 있었고, 다양한 논문들이 발표되고 있습니다. 어떤 특정한 주제나 질문이 있으신가요? 아니면 추천할 만한 논문이나 자료를 찾고 계신가요?\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "대화 요약:\n",
      "\n",
      "사용자는 \"안녕하세요? 반갑습니다. 제 이름은 테디입니다.\"라고 인사하며 자신을 소개했습니다. 이후, 사용자는 자신의 직업이 AI 연구원이라고 밝혔고, 현재 LLM(대규모 언어 모델)에 대해 연구하고 있으며 최근 논문을 읽고 있다고 언급했습니다. 대화 상대는 사용자의 관심 분야에 대해 질문하며 추가적인 도움을 제공할 준비가 되어 있음을 나타냈습니다.\n"
     ]
    }
   ],
   "source": [
    "# 사용자 입력 메시지 객체 생성\n",
    "input_message = HumanMessage(\n",
    "    content=\"최근 LLM 에 대해 좀 더 알아보고 있어요. LLM 에 대한 최근 논문을 읽고 있습니다.\"\n",
    ")\n",
    "\n",
    "# 메시지 내용 출력\n",
    "input_message.pretty_print()\n",
    "\n",
    "# 스트림 이벤트 실시간 처리 및 업데이트 출력\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
